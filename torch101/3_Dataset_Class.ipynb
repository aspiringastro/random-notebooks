{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d6cf103-06d9-4588-a514-2b9630f43e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92b4d6c6-5dbe-4387-bfb1-431ccb934384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative to class CustomDataset(torch.utils.data.Dataset):\n",
    "\n",
    "class CustomDataset:\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        curr_sample = self.data[idx, :]\n",
    "        curr_target = self.targets[idx]\n",
    "        return {\n",
    "            \"sample\": torch.tensor(curr_sample, dtype=torch.float),\n",
    "            \"target\": torch.tensor(curr_target, dtype=torch.long),\n",
    "        }\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfe59dee-e804-4797-8646-a91fd87ac85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       " \u001b[0mmake_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_informative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_redundant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_repeated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_clusters_per_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mflip_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mclass_sep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhypercube\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Generate a random n-class classification problem.\n",
       "\n",
       "This initially creates clusters of points normally distributed (std=1)\n",
       "about vertices of an ``n_informative``-dimensional hypercube with sides of\n",
       "length ``2*class_sep`` and assigns an equal number of clusters to each\n",
       "class. It introduces interdependence between these features and adds\n",
       "various types of further noise to the data.\n",
       "\n",
       "Without shuffling, ``X`` horizontally stacks features in the following\n",
       "order: the primary ``n_informative`` features, followed by ``n_redundant``\n",
       "linear combinations of the informative features, followed by ``n_repeated``\n",
       "duplicates, drawn randomly with replacement from the informative and\n",
       "redundant features. The remaining features are filled with random noise.\n",
       "Thus, without shuffling, all useful features are contained in the columns\n",
       "``X[:, :n_informative + n_redundant + n_repeated]``.\n",
       "\n",
       "Read more in the :ref:`User Guide <sample_generators>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "n_samples : int, default=100\n",
       "    The number of samples.\n",
       "\n",
       "n_features : int, default=20\n",
       "    The total number of features. These comprise ``n_informative``\n",
       "    informative features, ``n_redundant`` redundant features,\n",
       "    ``n_repeated`` duplicated features and\n",
       "    ``n_features-n_informative-n_redundant-n_repeated`` useless features\n",
       "    drawn at random.\n",
       "\n",
       "n_informative : int, default=2\n",
       "    The number of informative features. Each class is composed of a number\n",
       "    of gaussian clusters each located around the vertices of a hypercube\n",
       "    in a subspace of dimension ``n_informative``. For each cluster,\n",
       "    informative features are drawn independently from  N(0, 1) and then\n",
       "    randomly linearly combined within each cluster in order to add\n",
       "    covariance. The clusters are then placed on the vertices of the\n",
       "    hypercube.\n",
       "\n",
       "n_redundant : int, default=2\n",
       "    The number of redundant features. These features are generated as\n",
       "    random linear combinations of the informative features.\n",
       "\n",
       "n_repeated : int, default=0\n",
       "    The number of duplicated features, drawn randomly from the informative\n",
       "    and the redundant features.\n",
       "\n",
       "n_classes : int, default=2\n",
       "    The number of classes (or labels) of the classification problem.\n",
       "\n",
       "n_clusters_per_class : int, default=2\n",
       "    The number of clusters per class.\n",
       "\n",
       "weights : array-like of shape (n_classes,) or (n_classes - 1,),              default=None\n",
       "    The proportions of samples assigned to each class. If None, then\n",
       "    classes are balanced. Note that if ``len(weights) == n_classes - 1``,\n",
       "    then the last class weight is automatically inferred.\n",
       "    More than ``n_samples`` samples may be returned if the sum of\n",
       "    ``weights`` exceeds 1. Note that the actual class proportions will\n",
       "    not exactly match ``weights`` when ``flip_y`` isn't 0.\n",
       "\n",
       "flip_y : float, default=0.01\n",
       "    The fraction of samples whose class is assigned randomly. Larger\n",
       "    values introduce noise in the labels and make the classification\n",
       "    task harder. Note that the default setting flip_y > 0 might lead\n",
       "    to less than ``n_classes`` in y in some cases.\n",
       "\n",
       "class_sep : float, default=1.0\n",
       "    The factor multiplying the hypercube size.  Larger values spread\n",
       "    out the clusters/classes and make the classification task easier.\n",
       "\n",
       "hypercube : bool, default=True\n",
       "    If True, the clusters are put on the vertices of a hypercube. If\n",
       "    False, the clusters are put on the vertices of a random polytope.\n",
       "\n",
       "shift : float, ndarray of shape (n_features,) or None, default=0.0\n",
       "    Shift features by the specified value. If None, then features\n",
       "    are shifted by a random value drawn in [-class_sep, class_sep].\n",
       "\n",
       "scale : float, ndarray of shape (n_features,) or None, default=1.0\n",
       "    Multiply features by the specified value. If None, then features\n",
       "    are scaled by a random value drawn in [1, 100]. Note that scaling\n",
       "    happens after shifting.\n",
       "\n",
       "shuffle : bool, default=True\n",
       "    Shuffle the samples and the features.\n",
       "\n",
       "random_state : int, RandomState instance or None, default=None\n",
       "    Determines random number generation for dataset creation. Pass an int\n",
       "    for reproducible output across multiple function calls.\n",
       "    See :term:`Glossary <random_state>`.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "X : ndarray of shape (n_samples, n_features)\n",
       "    The generated samples.\n",
       "\n",
       "y : ndarray of shape (n_samples,)\n",
       "    The integer labels for class membership of each sample.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "make_blobs : Simplified variant.\n",
       "make_multilabel_classification : Unrelated generator for multilabel tasks.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The algorithm is adapted from Guyon [1] and was designed to generate\n",
       "the \"Madelon\" dataset.\n",
       "\n",
       "References\n",
       "----------\n",
       ".. [1] I. Guyon, \"Design of experiments for the NIPS 2003 variable\n",
       "       selection benchmark\", 2003.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/mambaforge/envs/torch101/lib/python3.10/site-packages/sklearn/datasets/_samples_generator.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "? make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d1dc9b3-cf12-4152-9f5f-f5530a86d260",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = make_classification(n_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8570035-639f-4723-b8f9-5b184208754e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 20), (1000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "099e7354-19df-4350-b81d-edd23f7c3735",
   "metadata": {},
   "outputs": [],
   "source": [
    "cds = CustomDataset(data=data, targets=targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10d0cb95-9e14-46b5-a52a-9534aad6a18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "016a870d-8ea1-48a3-a770-dc5e66cd18c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample': tensor([ 1.3423,  1.7112,  0.2341,  0.1518,  0.2507,  1.6193,  1.0517, -0.9491,\n",
       "          0.6201,  0.7879,  0.7326,  0.5672,  0.8102, -0.0574, -0.2574, -0.5856,\n",
       "          0.1536, -0.7466, -0.0576,  1.1617]),\n",
       " 'target': tensor(1)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d69eb87-623c-4d3e-bdde-fe6a806a063b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.3423,  1.7112,  0.2341,  0.1518,  0.2507,  1.6193,  1.0517, -0.9491,\n",
       "         0.6201,  0.7879,  0.7326,  0.5672,  0.8102, -0.0574, -0.2574, -0.5856,\n",
       "         0.1536, -0.7466, -0.0576,  1.1617])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cds[0][\"sample\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a4ee735-387b-4fb6-a8eb-f8af15fc4b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cds[0][\"sample\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25009d84-9d9d-4166-a547-d1accef74098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': tensor([ 1.3423,  1.7112,  0.2341,  0.1518,  0.2507,  1.6193,  1.0517, -0.9491,\n",
      "         0.6201,  0.7879,  0.7326,  0.5672,  0.8102, -0.0574, -0.2574, -0.5856,\n",
      "         0.1536, -0.7466, -0.0576,  1.1617]), 'target': tensor(1)}\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(cds)):\n",
    "    print(cds[idx])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65f706a-fbdf-41ac-8d9c-cc30699b5f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
